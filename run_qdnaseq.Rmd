---
title: "run_me.Rmd"
author: "Nadia Mohammed"
output: html_document
---

# QDNASeq pipeline

### Step 1: Install and Load libraries

```{r}
if (!require("tidyverse", quietly = TRUE))
    install.packages("tidyverse")
if (!require("devtools", quietly = TRUE))
    install.packages("devtools")
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("QDNAseq")

devtools::install_github(repo = "asntech/QDNAseq.hg38")

library(tidyverse)
library(QDNAseq)
library(QDNAseq.hg38)
```

### Step 2: Read in bin annotations for UCSC hg38 genome

Note: binsize can be adjusted. There are certain sizes that are supported (see qdnaseq.hg38 module for info)

```{r}
bins <- function(binsize){
  getBinAnnotations(binSize=binsize, genome="hg38")
}

binsize <- binsize
```

### Step 3: Read in BAM(s)

You can read in a directory of BAM files

```{r}
readCounts <- binReadCounts(bins, path = "<BAM_PATH>")
```

### Step 4: Run CNV calling algo
```{r}
#generate segmented read count plot
#segmentation used (sqrt(x + 3/8) to 
#stabilise variance of a Poisson distribution
#Blacklist filter set to 100 to not restrict filtering
#and allow overlap initially
copy_Numbers_segmented <- readCounts %>%
  applyFilters(residual=TRUE, blacklist=100) %>%
  # Estimate and correct read counts as a function of GC content and
  # mappability (removes further noise from e.g. FFPE)
  estimateCorrection() %>%
  correctBins() %>%

  # Normalise and smooth corrected read counts
  smoothOutlierBins()  %>%
  normalizeBins() %>%
  segmentBins(transformFun="sqrt")
```


```{r}
# Generate called read count plots
# for final CNV call profiles
copyNumbersCalled <- readCounts %>%

    # Filter reads based on a) residuals after fitting to a model, 
    # and b) on amount  of acceptable overlap with 
    # blacklisted (i.e. problematic) regions/known artifacts
    applyFilters(residual=TRUE, blacklist=100) %>%

    # Estimate and correct read counts as a function of GC content and
    # mappability (removes further noise from e.g. FFPE)
    estimateCorrection() %>%
    correctBins() %>%

    # Normalise and smooth corrected read counts
    normalizeBins() %>%
    smoothOutlierBins() %>%

    # Segment bins: i.e. group similar regions together
    # in a single "line" or "window" in terms of read count value
    segmentBins(transformFun="sqrt") %>%
    normalizeSegmentedBins() %>%
    callBins()
```

### Step 5: Save plot output

```{r}
png(filename = "%s_copy_number_segmented.png", width=1300, height=800)
plot(copy_Numbers_segmented)
dev.off()
png(filename = "%s_called_copy_numbers.png", width=1300, height=800)
plot(copyNumbersCalled)
dev.off()
```

### Step 6: Save tabular data

```{r}
## Summarised calls - one file per sample
QDNAseq::exportBins(copyNumbersCalled, format = "seg", type = "calls",
                    file = paste("%s.summarised_calls_binsize_",binsize,".tsv", sep = ""))
## Raw calls - one file that contains *all* samples together
QDNAseq::exportBins(copyNumbersCalled, format = "tsv", type = "calls",
                    file = paste("all_calls_binsize",binsize,"_merged.raw_calls_all_depths.tsv", sep = ""))
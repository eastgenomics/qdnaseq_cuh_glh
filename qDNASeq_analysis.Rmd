---
title: "qDNASeq"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# setwd("~/Documents/Projects/cancer/sWGS")
library(bedr)
library(dplyr)
library(ggplot2)
library(ggfortify)
library("ggpubr")
library(plotly) 
library(tidyr)
library(knitr)
```

# Introduction

This report investigates the output from qDNASeq and compare the output to WGS of the same sample from GEL. The study design is there are 8 patiensts, each with 2 FF sample and 2 FFPE samples, giving us a total of 32 samples. The samples have been processed on the NovaSeq machine using shallow WGS technique, therefore we expect very low coverages. The first part will look at general QC of the data, the second part will look at each sample in detail at different coverages (normal vs downsampled) and different bins, with comparison to WGS and concordance between tissue types.

``` {r functions}
# function to clean qDNASeq summarised data
make_bed_from_sum_df <- function(SWGS_sum) {
  # make loc column
  SWGS_sum$location <- paste(SWGS_sum$CHROMOSOME, SWGS_sum$START, sep=":")
  SWGS_sum$location <- paste(SWGS_sum$location, SWGS_sum$STOP, sep="-")
  # order and make bed file
  SWGS_sum <- as.data.frame(SWGS_sum$location)
  SWGS_sum <- as.data.frame(SWGS_sum[order(SWGS_sum$`SWGS_sum$location`),])
  # remove dup rows
  SWGS_sum <- as.data.frame(SWGS_sum[!duplicated(SWGS_sum), ])
  colnames(SWGS_sum) <- "location"
  SWGS_sum <- separate(data = SWGS_sum, col = location, into = c("chr", "start", "end"))

  return(SWGS_sum)
  
}

bed_intersect <- function(sample_bed, truth_bed){
  # both dataframes must be chr,start,end
  # truth is expected to have X or Y chr 
  # pred is not expected to have X or Y 
  
  # finds the interaction of the sample and truth bed file
  
  # convert truth data to int, do not touch chr
  truth_bed$start <- as.integer(truth_bed$start)
  truth_bed$end <- as.integer(truth_bed$end)

  # convert pred data to int
  sample_bed$chr <- as.character(sample_bed$chr)
  sample_bed$start <- as.integer(sample_bed$start)
  sample_bed$end <- as.integer(sample_bed$end)
  
  # sort the bed files
  truth_bed.sort <- bedr.sort.region(truth_bed, check.chr = F, verbose = F)
  sample_bed.sort <- bedr.sort.region(sample_bed, check.chr = F, verbose = F)
  
  # remove dup rows
  truth_bed.sort <- truth_bed.sort[!duplicated(truth_bed.sort), ] 
  sample_bed.sort <- sample_bed.sort[!duplicated(sample_bed.sort), ] 
  # intersect
  pred.int.truth <- bedr(
                      input = list(a = sample_bed.sort, b = truth_bed.sort),
                      method = "intersect",
                      params = "-loj -sorted",
                      check.chr = F, verbose = F, engine = "bedtools", check.valid = T)
  return(pred.int.truth)
  
}

bed_missed_in_sample <- function(sample_bed, truth_bed){
  # both dataframes must be chr,start,end
  # truth is expected to have X or Y chr 
  # pred is not expected to have X or Y 
  
  # finds the interaction of the sample and truth bed file
  
  # convert truth data to int, do not touch chr
  truth_bed$start <- as.integer(truth_bed$start)
  truth_bed$end <- as.integer(truth_bed$end)

  # convert pred data to int
  sample_bed$chr <- as.character(sample_bed$chr)
  sample_bed$start <- as.integer(sample_bed$start)
  sample_bed$end <- as.integer(sample_bed$end)
  
  # sort the bed files
  truth_bed.sort <- bedr.sort.region(truth_bed, check.chr = F, verbose = F)
  sample_bed.sort <- bedr.sort.region(sample_bed, check.chr = F, verbose = F)
  
  # remove dup rows
  truth_bed.sort <- truth_bed.sort[!duplicated(truth_bed.sort), ] 
  sample_bed.sort <- sample_bed.sort[!duplicated(sample_bed.sort), ] 
  # intersect
  pred.int.truth <- bedr(
                      input = list(a =truth_bed.sort , b = sample_bed.sort),
                      method = "intersect",
                      params = "-loj -sorted",
                      check.chr = F, verbose = F, engine = "bedtools", check.valid = T)
  return(pred.int.truth)
  
}
```

# Quality control

General QC can be found in the multiQC report on DNAnexus at: https://platform.dnanexus.com/projects/GQXY5k84926v43v88yY1FX5z/data/multiqc 
In this report we will look at the QualiMap coverages and the PCA plots

## QualiMap

sWGS targets to have low mapped reads, 5X should be sufficient to do CNV calling on. We can see in the boxplot below that the distribution is quiet varied with the mean coverage for this being 9X, higest is 21X and lowest is 0X

```{r qualimap}
qualimap <- read.csv("../qualimap_coverage.tsv", sep = "\t")
p <- ggplot(qualimap, aes(x=mean.coverageData)) +
  geom_boxplot() +
  geom_dotplot(stackdir='center', dotsize=0.30) +
  coord_flip() +
  theme_classic() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

p

```

## PCA plot

The PCA plot will indicate to us what the variation in our data is driven by. This will indicate any batch effects we should be aware of and take into consideration for downstream analysis. The data we will use in the raw data as it has the same bins applied and therefore the comparison is more useful than segment data where there is little overlap across all samples.

What we find is that variation is not driven by tissue difference, this means that the log2 mean ratio calculations is not associated with tissue type. This will allow to compare the data as normal and that any variation in data is not due to tissue type. We also wanted to see whether coverage drove any differences between the qDNASeq calculations and we can see that it didn't explain as there are samples near each other have having coverage calculation in either side of the coverage distribution for this sample.

```{r read_data}
# read  data in
mydir = "~/Documents/Projects/cancer/sWGS/"

### raw data
total_files =  list.files(path = paste0(mydir), pattern= ("*.raw_calls_all_depths.tsv"))
raw_df  <- as.data.frame(matrix(ncol = 0, nrow = 51019))

for(i in 1:length(total_files)) { #up to 4 samples
  file <- total_files[i]
  file_name <- strsplit(file, ".raw_calls_all_depths.tsv") #removes the .tsv taken from file name
  tsv_file <- read.csv(paste(mydir, "/", file, sep= ""), sep="\t", header = T) #read in the file as a dataframe
  raw_df <- cbind(raw_df, tsv_file)
  file_name <- file_name[[1]] #get the dataframe from the list
  assign(file_name, tsv_file) #assigns the tsv_file to the object file_name which is the dataframe
  file_name <- NULL
  tsv_file <- NULL
}

### summarised data
total_files =  list.files(path = paste0(mydir), pattern= ("*.summarised_calls.tsv"))
sum_df  <- as.data.frame(matrix(ncol = 6, nrow = 0))

for(i in 1:length(total_files)) { #up to 4 samples
  file <- total_files[i]
  file_name <- strsplit(file, ".summarised_calls.tsv") #removes the .tsv taken from file name
  tsv_file <- read.csv(paste(mydir, "/", file, sep= ""), sep="\t", header = T) #read in the file as a dataframe
  sum_df <- rbind(sum_df, tsv_file)
  file_name <- file_name[[1]] #get the dataframe from the list
  file_name <- gsub("_S.*", "", file_name)
  assign(file_name, tsv_file) #assigns the tsv_file to the object file_name which is the dataframe
  file_name <- NULL
  tsv_file <- NULL
}


metadata <- read.delim(paste(mydir, "metadata.txt", sep= "/"), sep = "\t")

```

```{r PCA_plot_all}
# transform the data to be readt for prcomp
raw_df_2 <- raw_df[ , grepl( "SWGS" , names( raw_df ) ) ]
traw_df_2 <- as.data.frame(t(raw_df_2))
colnames(traw_df_2) <- raw_df_2$feature
traw_df_2$samples <- gsub("_S.*","",rownames(traw_df_2))
traw_df_2$tissuetype <- metadata$Tissue.Type[match(metadata$samplename, traw_df_2$samples)]

## PCA plot
logration_df_pca <- prcomp(traw_df_2[,c(1:51019)],
                   center = TRUE)
logration_df_pca.plot <- autoplot(logration_df_pca,
                          data = traw_df_2,
                          colour = 'samples',
                          shape = 'tissuetype',
                          main = 'PCA plot using raw data')
logration_df_pca.plot
ggplotly(logration_df_pca.plot)

```


```{r}
# lets remove the "bad QC samples"
row2remove <- c("SWGS_N7_7096_S7_L001_markdup", "SWGS_N32_7276R_S32_L001_markdup", "SWGS_N11_1911_S11_L001_markdup")

traw_df_3 <- traw_df_2[!(row.names(traw_df_2) %in% row2remove), ]
logration_df_pca <- prcomp(traw_df_3[,c(1:51019)],
                   center = TRUE)
logration_df_pca.plot <- autoplot(logration_df_pca,
                          data = traw_df_3,
                          colour = 'samples',
                          shape = 'tissuetype',
                          main = 'PCA plot using raw data (removal of outliers N7, N32, N11)')
logration_df_pca.plot
ggplotly(logration_df_pca.plot)

# can try to plot using coverage os estimating point
traw_df_3$coverage <- qualimap$mean.coverageData[match(rownames(traw_df_3), qualimap$Sample)]
logration_df_pca.plot <- autoplot(logration_df_pca,
                          data = traw_df_3,
                          colour = 'coverage',
                          shape = 'tissuetype',
                          main = 'PCA plot using raw data (removal of outliers N7, N32, N11)')
logration_df_pca.plot
ggplotly(logration_df_pca.plot)
```

# Case analysis

## Case 2 



## Case 4 

### Normal Bin = 50kbp


```{r}
sample="CUH189"
# read in truth data
Case_WGS <- read.csv(paste(mydir, paste(sample, "CNVs.csv"), sep =""))

# output just the bed file
# remove chr 
Case_WGS$Position..hg38.<-gsub("chr","",as.character(Case_WGS$Position..hg38.))
Case_WGS_location <- separate(data = Case_WGS, col = Position..hg38., into = c("chr", "start", "end"))
Case_WGS_location_bed <- Case_WGS_location[,c("chr", "start", "end")]

# save the three columns
write.table(Case_WGS_location_bed, 
            file = paste(mydir, sample ," _targeted_CN_locs.tsv", sep =""),
            sep = "\t", col.names = F, row.names = F, quote = F)
```

#### How many TP, TN and FP when comparing our predicted CNs to the truth dataset

* Predicted sWGS CN overlapping with truth WGS CN = TP
* Predicted sWGS NOT present with truth WGS CN = TN
* Truth WGS CN NOT present in predicted sWGS CN = FP

```{r}
# get the summaried data for samples associated to this case
C_samples<- unique(metadata[which(metadata$CUH_number %in% sample), "samplename"])

Case_truthvspredicted_df <- as.data.frame(matrix(NA, nrow =4,ncol=3))
colnames(Case_truthvspredicted_df) <- c("TP", "FP", "TN")
rownames(Case_truthvspredicted_df) <- C_samples
# make a bed file output to do intersect with these 4 samples
print(paste("Truth WGS", sample, "has CN segements = ", nrow(Case_WGS)))
for(i in 1:length(C_samples)) { 
  N = C_samples[i]
  # assign the new samplename with  _bed to the new datafraame that contains loc,start,end
  assign(paste(N, "_bed", sep=""), make_bed_from_sum_df(get(N)))
  print(paste(N, " has CN segements = ", nrow( make_bed_from_sum_df(get(N))), sep = ""))
  # save the dataframe
  write.table(get(paste(N, "_bed", sep="")), file = paste(mydir, sample, "_" , N, "_predicted_CN_locs.tsv", sep=""), sep = "\t",
            col.names = F, row.names = F, quote = F)
  
  # compare to the truth dataset
  # contains all intersect with TP and FP
  intersect_loj <- bed_intersect(sample_bed = get(paste(N, "_bed", sep="")), truth_bed = Case_WGS_location_bed)
  # row = sample, column = TP
  # if true, all will be coordinates
  Case_truthvspredicted_df[i,1] <- nrow(intersect_loj[which(intersect_loj[,4] > 0),])
  # row = sample, column = FP
  # if FP, they will exist in 4,5,6 column (truth dataset) as -1
  Case_truthvspredicted_df[i,2] <- nrow(intersect_loj[which(intersect_loj[,4] == "."),])
  # row = sample, column = TN
  tmp <- bed_missed_in_sample(sample_bed =  get(paste(N, "_bed", sep="")), truth_bed = Case_WGS_location_bed)
  Case_truthvspredicted_df[i,3] <- nrow(tmp[which(tmp[,4] == "."),])
}

kable(Case_truthvspredicted_df, caption = paste(sample, "vs truth WGS dataset"))

```

## Case 5 

### Normal Bin = 50kbp


```{r}
sample="CUH190"
# read in truth data
Case_WGS <- read.csv(paste(mydir, paste(sample, "CNVs.csv"), sep =""))

# output just the bed file
# remove chr 
Case_WGS$Position..hg38.<-gsub("chr","",as.character(Case_WGS$Position..hg38.))
Case_WGS_location <- separate(data = Case_WGS, col = Position..hg38., into = c("chr", "start", "end"))
Case_WGS_location_bed <- Case_WGS_location[,c("chr", "start", "end")]

# save the three columns
write.table(Case_WGS_location_bed, 
            file = paste(mydir, sample ," _targeted_CN_locs.tsv", sep =""),
            sep = "\t", col.names = F, row.names = F, quote = F)
```

#### How many TP, TN and FP when comparing our predicted CNs to the truth dataset

* Predicted sWGS CN overlapping with truth WGS CN = TP
* Predicted sWGS NOT present with truth WGS CN = TN
* Truth WGS CN NOT present in predicted sWGS CN = FP

```{r}
# get the summaried data for samples associated to this case
C_samples<- unique(metadata[which(metadata$CUH_number %in% sample), "samplename"])

Case_truthvspredicted_df <- as.data.frame(matrix(NA, nrow =4,ncol=3))
colnames(Case_truthvspredicted_df) <- c("TP", "FP", "TN")
rownames(Case_truthvspredicted_df) <- C_samples
# make a bed file output to do intersect with these 4 samples
print(paste("Truth WGS", sample, "has CN segements = ", nrow(Case_WGS)))
for(i in 1:length(C_samples)) { 
  N = C_samples[i]
  # assign the new samplename with  _bed to the new datafraame that contains loc,start,end
  assign(paste(N, "_bed", sep=""), make_bed_from_sum_df(get(N)))
  print(paste(N, " has CN segements = ", nrow( make_bed_from_sum_df(get(N))), sep = ""))
  # save the dataframe
  write.table(get(paste(N, "_bed", sep="")), file = paste(mydir, sample, "_" , N, "_predicted_CN_locs.tsv", sep=""), sep = "\t",
            col.names = F, row.names = F, quote = F)
  
  # compare to the truth dataset
  # contains all intersect with TP and FP
  intersect_loj <- bed_intersect(sample_bed = get(paste(N, "_bed", sep="")), truth_bed = Case_WGS_location_bed)
  # row = sample, column = TP
  # if true, all will be coordinates
  Case_truthvspredicted_df[i,1] <- nrow(intersect_loj[which(intersect_loj[,4] > 0),])
  # row = sample, column = FP
  # if FP, they will exist in 4,5,6 column (truth dataset) as -1
  Case_truthvspredicted_df[i,2] <- nrow(intersect_loj[which(intersect_loj[,4] == "."),])
  # row = sample, column = TN
  tmp <- bed_missed_in_sample(sample_bed =  get(paste(N, "_bed", sep="")), truth_bed = Case_WGS_location_bed)
  Case_truthvspredicted_df[i,3] <- nrow(tmp[which(tmp[,4] == "."),])
}

kable(Case_truthvspredicted_df, caption = paste(sample, "vs truth WGS dataset"))

```



#### What are the common predicted in all 4, 3 and 2 samples
#### Are the repeats consistent in their raw copy number
#### Are the repeats consistent in their summarised segmented copy number
#### Compare the log2 ratio of bins






## Case 6 

### Normal Bin = 50kbp


```{r}
sample="CUH191"
# read in truth data
Case_WGS <- read.csv(paste(mydir, paste(sample, "CNVs.csv"), sep =""))

# output just the bed file
# remove chr 
Case_WGS$Position..hg38.<-gsub("chr","",as.character(Case_WGS$Position..hg38.))
Case_WGS_location <- separate(data = Case_WGS, col = Position..hg38., into = c("chr", "start", "end"))
Case_WGS_location_bed <- Case_WGS_location[,c("chr", "start", "end")]

# save the three columns
write.table(Case_WGS_location_bed, 
            file = paste(mydir, sample ," _targeted_CN_locs.tsv", sep =""),
            sep = "\t", col.names = F, row.names = F, quote = F)
```

#### How many TP, TN and FP when comparing our predicted CNs to the truth dataset

* Predicted sWGS CN overlapping with truth WGS CN = TP
* Predicted sWGS NOT present with truth WGS CN = TN
* Truth WGS CN NOT present in predicted sWGS CN = FP

```{r}
# get the summaried data for samples associated to this case
C_samples<- unique(metadata[which(metadata$CUH_number %in% sample), "samplename"])

Case_truthvspredicted_df <- as.data.frame(matrix(NA, nrow =4,ncol=3))
colnames(Case_truthvspredicted_df) <- c("TP", "FP", "TN")
rownames(Case_truthvspredicted_df) <- C_samples
# make a bed file output to do intersect with these 4 samples
print(paste("Truth WGS", sample, "has CN segements = ", nrow(Case_WGS)))
for(i in 1:length(C_samples)) { 
  N = C_samples[i]
  # assign the new samplename with  _bed to the new datafraame that contains loc,start,end
  assign(paste(N, "_bed", sep=""), make_bed_from_sum_df(get(N)))
  print(paste(N, " has CN segements = ", nrow( make_bed_from_sum_df(get(N))), sep = ""))
  # save the dataframe
  write.table(get(paste(N, "_bed", sep="")), file = paste(mydir, sample, "_" , N, "_predicted_CN_locs.tsv", sep=""), sep = "\t",
            col.names = F, row.names = F, quote = F)
  
  # compare to the truth dataset
  # contains all intersect with TP and FP
  intersect_loj <- bed_intersect(sample_bed = get(paste(N, "_bed", sep="")), truth_bed = Case_WGS_location_bed)
  # row = sample, column = TP
  # if true, all will be coordinates
  Case_truthvspredicted_df[i,1] <- nrow(intersect_loj[which(intersect_loj[,4] > 0),])
  # row = sample, column = FP
  # if FP, they will exist in 4,5,6 column (truth dataset) as -1
  Case_truthvspredicted_df[i,2] <- nrow(intersect_loj[which(intersect_loj[,4] == "."),])
  # row = sample, column = TN
  tmp <- bed_missed_in_sample(sample_bed =  get(paste(N, "_bed", sep="")), truth_bed = Case_WGS_location_bed)
  Case_truthvspredicted_df[i,3] <- nrow(tmp[which(tmp[,4] == "."),])
}

kable(Case_truthvspredicted_df, caption = paste(sample, "vs truth WGS dataset"))

```

# Downsampling to 5X

